{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3af5d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2b4885c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  =  YOLO(\"runs/detect/train/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "48573a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rects(image,coordinates=[],color=(0, 255, 0),text_tuple=None):\n",
    "    \n",
    "    for rects in coordinates:\n",
    "        x,y,w,h =  rects\n",
    "        rect_image =cv2.rectangle(image,(x,y),(w,h),color, 2)\n",
    "        if text_tuple :\n",
    "            rect_image = cv2.putText(text_tuple)\n",
    "    \n",
    "    return rect_image\n",
    "\n",
    "\n",
    "def track_images(image_path, model):\n",
    "    coordinates = []\n",
    "    rect_images =  []\n",
    "    # Run prediction and convert results to DataFrame\n",
    "    results = model.predict(image_path)[0].boxes.data.detach().cpu().numpy()\n",
    "    df = pd.DataFrame(results,columns=[\"x1\",\"y1\",\"x2\",\"y2\",\"conf\",\"class_id\"]).astype(\"float\")\n",
    "    \n",
    "    # Iterate through each detection\n",
    "    for _, row in df.iterrows():\n",
    "        x1, y1, x2, y2, conf,_ = row  # it has only one class thus not needed\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        coordinates.append([x1, y1, x2, y2])\n",
    "        rect_image = cv2.imread(image_path)[y1:y2, x1:x2]\n",
    "        rect_images.append(rect_image)\n",
    "    \n",
    "    return (df,coordinates,conf,rect_images)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def draw_bounding_boxes(image, detections, threshold=0.25):\n",
    "    for bbox, text, score in detections:\n",
    "        if score > threshold:\n",
    "            cv2.rectangle(image, tuple(map(int, bbox[0])), tuple(map(int, bbox[2])), (0, 255, 0), 5)\n",
    "            cv2.putText(image, text, tuple(map(int, bbox[0])), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.65, (255, 0, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "56a52249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\RISHABH\\Pictures\\images\\plate2.jpg: 448x640 1 clone-license-plate, 140.2ms\n",
      "Speed: 2.5ms preprocess, 140.2ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "df,coordinates,conf,img =  track_images(\"C:/Users/RISHABH/Pictures/images/plate2.jpg\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "23890fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[104, 114, 121],\n",
       "        [104, 114, 121],\n",
       "        [107, 116, 120],\n",
       "        ...,\n",
       "        [ 37,  49,  51],\n",
       "        [ 52,  64,  66],\n",
       "        [ 64,  76,  78]],\n",
       "\n",
       "       [[ 70,  80,  87],\n",
       "        [ 65,  75,  82],\n",
       "        [ 68,  77,  81],\n",
       "        ...,\n",
       "        [ 33,  45,  47],\n",
       "        [ 51,  63,  65],\n",
       "        [ 66,  78,  80]],\n",
       "\n",
       "       [[ 43,  53,  60],\n",
       "        [ 29,  39,  46],\n",
       "        [ 30,  39,  43],\n",
       "        ...,\n",
       "        [ 28,  40,  42],\n",
       "        [ 49,  61,  63],\n",
       "        [ 67,  79,  81]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[100, 104, 105],\n",
       "        [ 63,  65,  66],\n",
       "        [ 27,  29,  30],\n",
       "        ...,\n",
       "        [ 30,  31,  27],\n",
       "        [ 64,  65,  61],\n",
       "        [ 97,  98,  94]],\n",
       "\n",
       "       [[102, 104, 104],\n",
       "        [ 65,  67,  67],\n",
       "        [ 28,  30,  30],\n",
       "        ...,\n",
       "        [ 34,  35,  31],\n",
       "        [ 67,  68,  64],\n",
       "        [101, 102,  98]],\n",
       "\n",
       "       [[101, 105, 106],\n",
       "        [ 65,  67,  68],\n",
       "        [ 29,  31,  32],\n",
       "        ...,\n",
       "        [ 35,  38,  36],\n",
       "        [ 68,  72,  67],\n",
       "        [101, 104, 102]]], shape=(68, 222, 3), dtype=uint8)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33dd35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "c:\\codes\\Lab\\Number_plate_recognitio\\plate\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected: 'N' with confidence: 0.93\n",
      "Detected: '1075' with confidence: 0.65\n",
      "Detected: 'CMI' with confidence: 0.38\n",
      "Detected: '06' with confidence: 0.62\n",
      "Detected: '21' with confidence: 0.17\n"
     ]
    }
   ],
   "source": [
    "img_ = np.array(Image.fromarray(img[0]))\n",
    "reader = easyocr.Reader(['en'], gpu=False)\n",
    "text_detections = reader.readtext(img_)\n",
    "final_text = \"\"\n",
    "for bbox, text, confidence in text_detections:\n",
    "    final_text += text + \" \"\n",
    "    print(f\"Detected: '{text}' with confidence: {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "35663413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(text_detections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6b703b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img[0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fd027084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N 1075 CMI 06 21 '"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
